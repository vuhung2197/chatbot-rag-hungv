# MIGRATION PLAN: MySQL â†’ PostgreSQL

**NgÃ y táº¡o:** 2026-01-23  
**Project:** English Chatbot  
**Má»©c Ä‘á»™:** ğŸ”´ CRITICAL - Full Database Migration  
**Thá»i gian Æ°á»›c tÃ­nh:** 2-3 tuáº§n  

---

## ğŸ“Š EXECUTIVE SUMMARY

### LÃ½ do Migration
- âœ… **Better JSON support** - PostgreSQL native JSON/JSONB
- âœ… **Advanced features** - Array types, full-text search, pgvector for embeddings
- âœ… **Scalability** - Better performance vá»›i large datasets
- âœ… **ACID compliance** - Stronger data integrity
- âœ… **Open source ecosystem** - Active community, better extensions

### Scope
- **Database:** MySQL 8.0 â†’ PostgreSQL 15+
- **Tables:** ~20 tables (users, wallets, subscriptions, knowledge_base, etc.)
- **Features affected:**
  - Authentication & Sessions
  - Wallet & Payment system
  - Knowledge Base & RAG
  - Subscriptions & Usage tracking
  - Vector embeddings

---

## ğŸ” CURRENT STATE ANALYSIS

### MySQL Usage in Project

**1. Connection Layer:**
```javascript
// backend/db.js
import mysql from 'mysql2/promise';
const pool = mysql.createPool({...});
```

**2. Query Patterns:**
- âœ… `pool.execute()` - Parameterized queries (166+ instances)
- âœ… Transactions with connection.beginTransaction()
- âœ… JSON columns (embedding, metadata, features)
- âš ï¸ ENUM types (nhiá»u columns)
- âš ï¸ FULLTEXT indexes
- âš ï¸ MySQL-specific syntax

**3. Key Tables:**
```
users (authentication)
user_sessions (JWT sessions)
user_wallets (payment)
wallet_transactions (payment history)
subscription_tiers (plans)
knowledge_base (AI/RAG)
knowledge_chunks (vector embeddings)
```

---

## ğŸ“‹ MIGRATION STRATEGY

### Phase-Based Approach

#### **Phase 1: Preparation** (Week 1)
1. Setup PostgreSQL development environment
2. Schema conversion & validation
3. Create migration scripts
4. Setup testing environment

#### **Phase 2: Code Adaptation** (Week 2)
1. Replace mysql2 vá»›i pg
2. Convert SQL syntax
3. Update queries
4. Test modifications

#### **Phase 3: Data Migration** (Week 2-3)
1. Export data tá»« MySQL
2. Transform & load vÃ o PostgreSQL
3. Verify data integrity
4. Performance testing

#### **Phase 4: Deployment** (Week 3)
1. Blue-green deployment setup
2. Production migration
3. Monitoring & rollback plan
4. Post-migration optimization

---

## ğŸ—„ï¸ SCHEMA CONVERSION

### Major Differences

| MySQL | PostgreSQL | Action Required |
|-------|------------|-----------------|
| `AUTO_INCREMENT` | `SERIAL` / `IDENTITY` | âœ… Convert primary keys |
| `ENUM('a','b')` | `CHECK` / `ENUM type` | âœ… Create custom types |
| `TINYINT(1)` | `BOOLEAN` | âœ… Convert boolean fields |
| `VARCHAR(255)` | `VARCHAR(255)` | âœ… Keep same |
| `TEXT` | `TEXT` | âœ… Keep same |
| `JSON` | `JSON` / `JSONB` | âœ… Upgrade to JSONB |
| `TIMESTAMP` | `TIMESTAMP` | âš ï¸ Timezone handling |
| `FULLTEXT` | `tsvector` / `GIN` | âœ… Rebuild FTS |
| `ENGINE=InnoDB` | N/A | âŒ Remove |
| `CHARSET utf8mb4` | N/A | âŒ Remove (default UTF-8) |

---

## ğŸ”§ CODE CHANGES REQUIRED

### 1. Database Connection

**BEFORE (MySQL):**
```javascript
import mysql from 'mysql2/promise';

const pool = mysql.createPool({
  host: process.env.DB_HOST,
  user: process.env.DB_USER,
  password: process.env.DB_PASSWORD,
  database: process.env.DB_DATABASE,
  port: 3306,
  charset: 'utf8mb4',
});
```

**AFTER (PostgreSQL):**
```javascript
import pkg from 'pg';
const { Pool } = pkg;

const pool = new Pool({
  host: process.env.DB_HOST,
  user: process.env.DB_USER,
  password: process.env.DB_PASSWORD,
  database: process.env.DB_DATABASE,
  port: 5432,
  // PostgreSQL defaults to UTF-8
});
```

### 2. Query API Differences

**MySQL2:**
```javascript
const [rows, fields] = await pool.execute('SELECT * FROM users WHERE id = ?', [userId]);
const user = rows[0];
```

**PostgreSQL (pg):**
```javascript
const result = await pool.query('SELECT * FROM users WHERE id = $1', [userId]);
const user = result.rows[0];
```

**Key Changes:**
- âŒ `pool.execute()` â†’ âœ… `pool.query()`
- âŒ `?` placeholders â†’ âœ… `$1, $2, $3` placeholders
- âŒ `[rows, fields]` â†’ âœ… `result.rows`

### 3. Transaction Pattern

**MySQL2:**
```javascript
const connection = await pool.getConnection();
await connection.beginTransaction();
try {
  await connection.execute('...');
  await connection.commit();
} catch (err) {
  await connection.rollback();
} finally {
  connection.release();
}
```

**PostgreSQL:**
```javascript
const client = await pool.connect();
try {
  await client.query('BEGIN');
  await client.query('...');
  await client.query('COMMIT');
} catch (err) {
  await client.query('ROLLBACK');
  throw err;
} finally {
  client.release();
}
```

---

## ğŸ“Š DETAILED SCHEMA CONVERSION

### Example: users table

**MySQL:**
```sql
CREATE TABLE users (
  id INT AUTO_INCREMENT PRIMARY KEY,
  name VARCHAR(100) NOT NULL,
  email VARCHAR(150) NOT NULL UNIQUE,
  password_hash TEXT NOT NULL,
  role ENUM('user', 'admin') DEFAULT 'user',
  email_verified TINYINT(1) NOT NULL DEFAULT 0,
  account_status ENUM('active','suspended','deleted') NOT NULL DEFAULT 'active',
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

**PostgreSQL:**
```sql
-- Create ENUM types first
CREATE TYPE user_role AS ENUM ('user', 'admin');
CREATE TYPE account_status AS ENUM ('active', 'suspended', 'deleted');

CREATE TABLE users (
  id SERIAL PRIMARY KEY,
  name VARCHAR(100) NOT NULL,
  email VARCHAR(150) NOT NULL UNIQUE,
  password_hash TEXT NOT NULL,
  role user_role DEFAULT 'user',
  email_verified BOOLEAN NOT NULL DEFAULT false,
  account_status account_status NOT NULL DEFAULT 'active',
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Trigger for updated_at (PostgreSQL doesn't have ON UPDATE)
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
  NEW.updated_at = CURRENT_TIMESTAMP;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER update_users_updated_at
BEFORE UPDATE ON users
FOR EACH ROW
EXECUTE FUNCTION update_updated_at_column();
```

---

## ğŸš€ IMPLEMENTATION PLAN

### Tools & Libraries

```json
{
  "dependencies": {
    "pg": "^8.11.3",              // PostgreSQL client
    "pg-format": "^1.0.4",        // SQL formatting
    "@types/pg": "^8.10.9"        // TypeScript types
  },
  "devDependencies": {
    "pgtyped": "^2.3.0",          // Type-safe queries (optional)
    "node-pg-migrate": "^6.2.2"   // Migration tool
  }
}
```

### Migration Scripts Structure

```
db/
â”œâ”€â”€ postgresql/
â”‚   â”œâ”€â”€ 001_init_schema.sql
â”‚   â”œâ”€â”€ 002_create_enums.sql
â”‚   â”œâ”€â”€ 003_create_tables.sql
â”‚   â”œâ”€â”€ 004_create_indexes.sql
â”‚   â”œâ”€â”€ 005_create_triggers.sql
â”‚   â”œâ”€â”€ 006_create_views.sql
â”‚   â””â”€â”€ 007_seed_data.sql
â”œâ”€â”€ migration/
â”‚   â”œâ”€â”€ export_mysql_data.js
â”‚   â”œâ”€â”€ transform_data.js
â”‚   â”œâ”€â”€ import_postgresql_data.js
â”‚   â””â”€â”€ verify_migration.js
â””â”€â”€ rollback/
    â””â”€â”€ mysql_backup_schema.sql
```

---

## ğŸ”„ DATA MIGRATION PROCESS

### Step 1: Export from MySQL

```bash
# Full dump
mysqldump -u root -p \
  --skip-triggers \
  --complete-insert \
  --no-create-info \
  chatbot > mysql_data_export.sql

# Per-table export (for large tables)
mysqldump -u root -p chatbot users > users_data.sql
mysqldump -u root -p chatbot knowledge_chunks > knowledge_chunks_data.sql
```

### Step 2: Transform Data

```javascript
// Example: Convert ENUM to PostgreSQL format
// MySQL: ENUM stored as index (0,1,2)
// PostgreSQL: ENUM stored as string ('user','admin')

const transformUserRole = (mysqlRole) => {
  const roleMap = { 0: 'user', 1: 'admin' };
  return roleMap[mysqlRole] || 'user';
};
```

### Step 3: Load into PostgreSQL

```bash
# Using psql
psql -U postgres -d chatbot -f postgresql_schema.sql
psql -U postgres -d chatbot -f transformed_data.sql

# Or using Node.js pg-copy-streams for large tables
```

---

## âœ… TESTING CHECKLIST

### Unit Tests
- [ ] Connection pooling works
- [ ] Queries return expected results
- [ ] Transactions rollback correctly
- [ ] JSON/JSONB operations work

### Integration Tests
- [ ] Authentication flow
- [ ] Wallet transactions
- [ ] Knowledge base search
- [ ] Subscription management

### Performance Tests
- [ ] Query performance benchmarks
- [ ] Connection pool under load
- [ ] Large result set handling
- [ ] Vector similarity search (embeddings)

### Data Integrity Tests
- [ ] Row counts match
- [ ] Primary keys sequence
- [ ] Foreign key constraints
- [ ] Unique constraints
- [ ] Check constraints

---

## ğŸ¯ SUCCESS CRITERIA

âœ… **Zero data loss**  
âœ… **<5% performance degradation** (or improvement)  
âœ… **All tests passing**  
âœ… **Production uptime >99.9%**  
âœ… **Rollback plan tested**

---

## âš ï¸ RISKS & MITIGATION

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| Data loss during migration | ğŸ”´ HIGH | LOW | Full backup + dry run + verify |
| Downtime > 4 hours | ğŸŸ¡ MEDIUM | MEDIUM | Blue-green deployment |
| Query performance issues | ğŸŸ¡ MEDIUM | MEDIUM | Benchmark before/after |
| Code bugs in conversion | ğŸŸ¡ MEDIUM | HIGH | Comprehensive testing |
| Rollback needed | ğŸŸ¡ MEDIUM | LOW | Keep MySQL running parallel |

---

## ğŸ“ ROLLBACK PLAN

### If migration fails:

1. **Stop application** (maintenance mode)
2. **Switch connection** back to MySQL
3. **Restart services** with MySQL config
4. **Analyze failure** cause
5. **Fix issues** before retry

### Parallel Running (Week 1-2 after migration)

- Keep MySQL read-only backup
- Monitor PostgreSQL performance
- Compare query results
- Ready to rollback if needed

---

## ğŸ’° COST ANALYSIS

### Development Time
- Schema conversion: 16 hours
- Code refactoring: 40 hours
- Testing: 24 hours
- Migration execution: 8 hours
- **Total:** ~88 hours (2 weeks)

### Infrastructure
- PostgreSQL hosting: Similar to MySQL
- Migration tools: Free (all open source)
- Testing environment: Temporary (1 month)

---

## ğŸ“ LEARNING RESOURCES

### PostgreSQL Essentials
- [Official PostgreSQL Docs](https://www.postgresql.org/docs/)
- [PostgreSQL vs MySQL](https://wiki.postgresql.org/wiki/Why_PostgreSQL_Instead_of_MySQL)
- [JSON/JSONB in PostgreSQL](https://www.postgresql.org/docs/current/datatype-json.html)

### Migration Guides
- [MySQL to PostgreSQL Migration Guide](https://wiki.postgresql.org/wiki/Converting_from_other_Databases_to_PostgreSQL#MySQL)
- [pg_chameleon](https://github.com/the4thdoctor/pg_chameleon) - MySQL to PostgreSQL replication

---

## ğŸ“… TIMELINE

```
Week 1: Preparation & Setup
â”œâ”€ Day 1-2: PostgreSQL setup, schema conversion
â”œâ”€ Day 3-4: Migration scripts development
â””â”€ Day 5: Testing environment validation

Week 2: Code Adaptation
â”œâ”€ Day 1-2: Update db.js, query functions
â”œâ”€ Day 3-4: Convert all controllers
â””â”€ Day 5: Integration testing

Week 3: Migration & Deployment
â”œâ”€ Day 1-2: Data migration dry run
â”œâ”€ Day 3: Production migration
â”œâ”€ Day 4-5: Monitoring & optimization
â””â”€ Week 3+: Parallel running, ready to rollback
```

---

## ğŸš€ NEXT STEPS

1. **Get Approval** - Stakeholder sign-off
2. **Setup Environment** - PostgreSQL dev/staging
3. **Create Schemas** - Convert all SQL files
4. **Refactor Code** - Update connection & queries
5. **Test Thoroughly** - All test suites passing
6. **Migrate Data** - Execute migration plan
7. **Monitor** - Performance & errors
8. **Optimize** - Indexes, queries, config

---

**Status:** ğŸ“‹ READY FOR REVIEW  
**Next Action:** Begin Phase 1 - PostgreSQL Setup  
**Owner:** Development Team  
**Deadline:** 3 weeks from approval

---

**End of Migration Plan**
