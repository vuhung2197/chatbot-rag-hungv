# ğŸ”„ Luá»“ng Xá»­ LÃ½ Advanced RAG - Chi Tiáº¿t (Updated)

**PhiÃªn báº£n:** 2.0 (TÃ­ch há»£p Intent Router)
**Cáº­p nháº­t láº§n cuá»‘i:** 05/02/2026

## ğŸ“‹ Tá»•ng Quan

Há»‡ thá»‘ng Chatbot hiá»‡n táº¡i sá»­ dá»¥ng kiáº¿n trÃºc **Advanced RAG** vá»›i **Intent Routing** lÃ m cá»•ng vÃ o (Gateway). Há»‡ thá»‘ng khÃ´ng Ã¡p dá»¥ng RAG má»™t cÃ¡ch mÃ¹ quÃ¡ng cho má»i cÃ¢u há»i mÃ  phÃ¢n loáº¡i Ã½ Ä‘á»‹nh ngÆ°á»i dÃ¹ng trÆ°á»›c Ä‘á»ƒ chá»n chiáº¿n lÆ°á»£c tráº£ lá»i tá»‘i Æ°u:
1.  **Giao tiáº¿p xÃ£ giao (Greeting):** Tráº£ lá»i nhanh báº±ng LLM, khÃ´ng tá»‘n tÃ i nguyÃªn RAG.
2.  **Há»i kiáº¿n thá»©c (Knowledge):** KÃ­ch hoáº¡t Advanced RAG Pipeline (Hybrid Search -> Re-ranking -> Reasoning).
3.  **Chá»§ Ä‘á» cáº¥m (Off-topic):** Tá»« chá»‘i tráº£ lá»i dá»±a trÃªn Policy.

---

## ğŸ—ï¸ Luá»“ng Xá»­ LÃ½ Tá»•ng Thá»ƒ

```mermaid
graph TD
    UserInput[User Input] --> Router{0. Intent Router}
    
    %% NhÃ¡nh 1: Greeting
    Router -- GREETING --> DirectLLM[Direct LLM Reply]
    DirectLLM --> Response
    
    %% NhÃ¡nh 2: Off-topic
    Router -- OFF_TOPIC --> Refusal[Safety Refusal]
    Refusal --> Response
    
    %% NhÃ¡nh 3: Knowledge (RAG Pipeline)
    Router -- KNOWLEDGE --> RAG_Start((Start RAG))
    
    subgraph "Advanced RAG Pipeline"
        RAG_Start --> Embedding[1. Embedding Generation]
        Embedding --> Adaptive[2. Adaptive Retrieval Params]
        Adaptive --> HybridSearch{3. Hybrid Search}
        
        HybridSearch --> Vector[Vector Search]
        HybridSearch --> FullText[Full-Text Search]
        
        Vector --> RRF[4. RRF Fusion]
        FullText --> RRF
        
        RRF --> ReRanking[5. Cohere Re-ranking]
        ReRanking --> Threshold{Score > 0.3?}
        
        Threshold -- No --> NoKnowledge[Fallback: I don't know]
        Threshold -- Yes --> Synthesis[6. Context Synthesis]
        
        Synthesis --> Clustering[Semantic Clustering]
        Synthesis --> Reasoning[Multi-hop Reasoning]
        
        Clustering --> Fusion[7. Context Fusion]
        Reasoning --> Fusion
        
        Fusion --> Generation[8. LLM Generation]
    end
    
    Generation --> Response
    NoKnowledge --> Response
```

---

## ğŸ“ PhÃ¢n TÃ­ch Chi Tiáº¿t Tá»«ng BÆ°á»›c (Code Level)

### **BÆ°á»›c 0: Intent Routing (Äá»‹nh Tuyáº¿n Ã Äá»‹nh)**
*Cá»•ng vÃ o thÃ´ng minh cá»§a há»‡ thá»‘ng.*

*   **File:** `backend/services/intentRouter.js`
*   **HÃ m:** `classifyIntent(message, model)`
*   **Logic:**
    *   Gá»i model LLM nhá» (GPT-4o-mini) vá»›i `temperature=0.1` (gáº§n nhÆ° deterministic).
    *   **System Prompt:** Ã‰p model tráº£ vá» JSON `{ "intent": "...", "reasoning": "..." }`.
    *   **PhÃ¢n loáº¡i:**
        *   `GREETING`: "Xin chÃ o", "Cáº£m Æ¡n" -> **Direct Reply**.
        *   `OFF_TOPIC`: ChÃ­nh trá»‹, báº¡o lá»±c -> **Block**.
        *   `KNOWLEDGE`: Há»i thÃ´ng tin -> **RAG**.
    *   **Fallback:** Náº¿u JSON lá»—i -> Máº·c Ä‘á»‹nh lÃ  `KNOWLEDGE` (thÃ  tÃ¬m thá»«a cÃ²n hÆ¡n bá» sÃ³t).
*   **Táº¡i sao quan trá»ng?** Giáº£m 30-50% chi phÃ­ vÃ  Ä‘á»™ trá»… báº±ng cÃ¡ch bá» qua RAG cho cÃ¡c cÃ¢u cÃ¢u xÃ£ giao Ä‘Æ¡n giáº£n.

---

### **BÆ°á»›c 1: Embedding Generation**
*Chuyá»ƒn Ä‘á»•i cÃ¢u há»i thÃ nh vector.*

*   **File:** `backend/services/embeddingVector.js`
*   **HÃ m:** `getEmbedding(text)`
*   **Logic:**
    *   Sá»­ dá»¥ng API `text-embedding-3-small` cá»§a OpenAI.
    *   Output: Vector 1536 chiá»u.
    *   ÄÃ¢y lÃ  Ä‘áº§u vÃ o báº¯t buá»™c cho Vector Search á»Ÿ bÆ°á»›c sau.

---

### **BÆ°á»›c 2: Adaptive Retrieval (ThÃ­ch á»¨ng)**
*Äo ni Ä‘Ã³ng giÃ y tham sá»‘ tÃ¬m kiáº¿m.*

*   **File:** `backend/services/advancedRAGFixed.js`
*   **HÃ m:** `adaptiveRetrieval(question)`
*   **Logic:**
    *   PhÃ¢n tÃ­ch tá»« khÃ³a Ä‘á»ƒ xÃ¡c Ä‘á»‹nh Ä‘á»™ phá»©c táº¡p:
        *   "so sÃ¡nh", "khÃ¡c biá»‡t" -> **Complex** -> TÄƒng `maxChunks` lÃªn 10-15, báº­t `MultiHop`.
        *   ÄÆ¡n giáº£n -> **Simple** -> `maxChunks` = 5, táº¯t cÃ¡c tÃ­nh nÄƒng nÃ¢ng cao.
    *   Má»¥c Ä‘Ã­ch: CÃ¢n báº±ng giá»¯a Performance (tá»‘c Ä‘á»™) vÃ  Quality (Ä‘á»™ sÃ¢u).

---

### **BÆ°á»›c 3: Hybrid Search (TÃ¬m Kiáº¿m Lai)**
*LÆ°á»›i Ä‘Ã¡nh cÃ¡ 2 lá»›p: Báº¯t Ã½ nghÄ©a vÃ  báº¯t tá»« khÃ³a.*

*   **File:** `backend/services/advancedRAGFixed.js`
*   **HÃ m:** `multiStageRetrieval(embedding, question)`
*   **Logic (Cháº¡y song song):**
    1.  **Vector Search:** `embedding <=> vector` (Cosine distance). TÃ¬m cÃ¡c Ä‘oáº¡n vÄƒn cÃ³ *Ã½ nghÄ©a* tÆ°Æ¡ng Ä‘á»“ng.
        *   Cháº¡y 2 pass: High threshold (0.65) vÃ  Medium threshold (0.45).
    2.  **Full-Text Search:** `to_tsvector @@ to_tsquery`. TÃ¬m cÃ¡c Ä‘oáº¡n vÄƒn cÃ³ *tá»« khÃ³a* chÃ­nh xÃ¡c (quan trá»ng cho tÃªn riÃªng, thuáº­t ngá»¯ ká»¹ thuáº­t).
*   **Káº¿t há»£p:** CÃ¡c káº¿t quáº£ Ä‘Æ°á»£c Ä‘Æ°a vÃ o bÆ°á»›c 4.

---

### **BÆ°á»›c 4: Reciprocal Rank Fusion (RRF)**
*Trá»™n káº¿t quáº£ cÃ´ng báº±ng.*

*   **File:** `backend/services/advancedRAGFixed.js`
*   **HÃ m:** `reciprocalRankFusion(vectorResults, textResults)`
*   **Logic:**
    *   VÃ¬ Ä‘iá»ƒm sá»‘ cosine (0.0-1.0) vÃ  Ä‘iá»ƒm full-text (khÃ´ng giá»›i háº¡n) khÃ´ng so sÃ¡nh Ä‘Æ°á»£c vá»›i nhau, ta dÃ¹ng **Thá»© Háº¡ng (Rank)**.
    *   CÃ´ng thá»©c: `Score = 1 / (k + Rank)`.
    *   Chunk nÃ o xuáº¥t hiá»‡n á»Ÿ top cáº£ 2 danh sÃ¡ch sáº½ cÃ³ Ä‘iá»ƒm RRF ráº¥t cao -> Æ¯u tiÃªn chá»n.

---

### **BÆ°á»›c 5: Re-ranking & Thresholding**
*Bá»™ lá»c tinh nhuá»‡.*

*   **File:** `backend/services/advancedRAGFixed.js`
*   **HÃ m:** `rerankContext(chunks, question)`
*   **Logic:**
    *   **Æ¯u tiÃªn 1 (Cohere AI):** Náº¿u cÃ³ key, gá»i model Rerank chuyÃªn dá»¥ng. Model nÃ y "Ä‘á»c" ká»¹ tá»«ng cáº·p (CÃ¢u há»i - Chunk) Ä‘á»ƒ cháº¥m Ä‘iá»ƒm Ä‘á»™ liÃªn quan thá»±c sá»±.
    *   **Æ¯u tiÃªn 2 (Heuristic):** TÃ­nh thá»§ cÃ´ng dá»±a trÃªn keyword overlap vÃ  semantic similarity.
    *   **Thresholding (Chá»‘t cháº·n):** Loáº¡i bá» tháº³ng tay cÃ¡c chunks cÃ³ Ä‘iá»ƒm < 0.3.
    *   **Káº¿t quáº£:** Náº¿u danh sÃ¡ch rá»—ng sau khi lá»c -> Tráº£ vá» "TÃ´i khÃ´ng biáº¿t" ngay láº­p tá»©c (Chá»‘ng áº£o giÃ¡c).

---

### **BÆ°á»›c 6: Context Synthesis & Fusion**
*Náº¥u cá»— cho LLM.*

*   **File:** `backend/services/advancedRAGFixed.js`
*   **Logic:**
    1.  **Semantic Clustering:** NhÃ³m cÃ¡c chunk cÃ³ ná»™i dung lÃ¡ nÃ¡ nhau láº¡i (trÃ¡nh láº·p tin).
    2.  **Multi-Hop Reasoning (náº¿u cáº§n):** Tá»± Ä‘á»™ng tÃ¬m thÃªm chunk C náº¿u A vÃ  B gá»£i Ã½ Ä‘áº¿n C (dÃ¹ C khÃ´ng khá»›p cÃ¢u há»i gá»‘c).
    3.  **Fusion:** GhÃ©p táº¥t cáº£ láº¡i thÃ nh má»™t Ä‘oáº¡n vÄƒn báº£n Markdown cÃ³ cáº¥u trÃºc phÃ¢n cáº¥p:
        ```markdown
        # ThÃ´ng tin chÃ­nh
        ## Chá»§ Ä‘á» A...
        ## Chá»§ Ä‘á» B...
        # Má»‘i liÃªn káº¿t...
        ```

---

### **BÆ°á»›c 7: LLM Generation**
*Sinh cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng.*

*   **File:** `backend/modules/chat/chat.controller.js`
*   **HÃ m:** `askAdvancedChatGPT`
*   **Logic:**
    *   Input: `FusedContext` + `UserQuestion`.
    *   **System Prompt:** "Báº¡n lÃ  chuyÃªn gia... Tráº£ lá»i dá»±a trÃªn thÃ´ng tin cung cáº¥p... TrÃ­ch dáº«n nguá»“n...".
    *   Model sinh ra text tráº£ lá»i.

---

## ğŸ“Š Cáº¥u TrÃºc Dá»¯ Liá»‡u Pháº£n Há»“i (API Response)

```json
{
  "reply": "Markdown content...",
  "reasoning_steps": [
    "Intent identified as KNOWLEDGE",
    "Retrieved 15 chunks (Hybrid)",
    "Selected 4 chunks after Re-ranking",
    "Generated response..."
  ],
  "chunks_used": [
    {
      "id": 101,
      "title": "Document A",
      "score": 0.98,
      "source": "vector"
    }
  ],
  "metadata": {
    "processing_time": 2450,
    "total_chunks": 15,
    "model_used": "gpt-4o"
  }
}
```
